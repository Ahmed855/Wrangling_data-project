{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Reasons to Choose Houston,TX.\n",
    "\n",
    "For this project I choose Houston,Texas. I choose this city becouse I had lived there for several years during my study at University of Houston .So I'm familier with the city, also crating mapping and wringling the street data bring some great memories.\n",
    "\n",
    "https://www.openstreetmap.org/node/27526178\n",
    "\n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "- Assess the quality of the data for validity, accuracy, completeness, consistency and uniformity.\n",
    "- Parse and gather data from popular file formats such as .csv, .json, .xml, and .html\n",
    "- Process data from multiple files or very large files that can be cleaned programmatically.\n",
    "- Learn how to store, query, and aggregate data using SQL.\n",
    "\n",
    "\n",
    "### Data Assessment\n",
    "\n",
    "- Abbreviations of street types for example \"ST\", \"AV\"ØŒ\"DR\" etc.\n",
    "- All lowercase letters for example \"avenue\" instead of \"Avenue\".\n",
    "- iter through all zip codes, collect all the zip codes that does not start with 15 since pittsburgh PA zip codes with 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Auditing and cleaning The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports libraries\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import csv\n",
    "import codecs\n",
    "import schema\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#osm file\n",
    "OSMFILE = \"houston_texas.osm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if elem.tag in tags: \n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "    return tags\n",
    "    \n",
    "\"\"\"\n",
    "return tag type as well as count for each tag.\n",
    "\"\"\"\n",
    "pprint.pprint(count_tags(OSMFILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  k Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Count multiple patterns in the tags\n",
    "\"\"\"\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        \n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "\n",
    "    return keys\n",
    "    \n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(process_map(OSMFILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique users\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The unique users have contributed to the data set\n",
    "\n",
    "The function process_map should return a set of unique user IDs\n",
    "\"\"\"\n",
    "\n",
    "def get_user(element):\n",
    "    return\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if \"uid\" in element.attrib:\n",
    "            users.add(element.attrib[\"uid\"])\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing out the total number of unique users\n",
    "\n",
    "print(len(process_map(OSMFILE)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cleaning street names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regular expression compilers\n",
    "\n",
    "OSM_f = \"houston_texas.osm\"\n",
    "\n",
    "regex = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "regexc = re.compile(r'^[NSEW]\\b\\.?', re.IGNORECASE)  \n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Bend\", \"Chase\", \"Circle\", \"Cove\", \"Crossing\", \"Hill\",\n",
    "            \"Hollow\", \"Loop\", \"Park\", \"Pass\", \"Overlook\", \"Path\", \"Plaza\", \"Point\", \"Ridge\", \"Row\",\n",
    "            \"Run\", \"Terrace\", \"Walk\", \"Trace\", \"View\", \"Vista\"]\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"street\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Boulavard\": \"Boulevard\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"RD\": \"Road\",\n",
    "            \"Pl\": \"Place\",\n",
    "            \"Pl.\": \"Place\",\n",
    "            \"PKWY\": \"Parkway\",\n",
    "            \"Pkwy\": \"Parkway\",\n",
    "            \"Ln\": \"Lane\",\n",
    "            \"Ln.\": \"Lane\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Dr.\": \"Drive\"\n",
    "            }\n",
    "# Adding street names in dictionary by type\n",
    "# Takes two arguments: dictionary and string, whene string didn't match pattern it will adds it to dictionary. \n",
    "def audit_street_type(street_types, street_name, regex, expected):  \n",
    "    m = regex.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checks if attribute is a street \n",
    "#Args:\n",
    "#elem: Element from OpenStreetMap data\n",
    "#Returns:\n",
    "#True if a valid street name. False otherwise.\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parsing and auditing of the street names.\n",
    "def audit(osm_file, regex):\n",
    "    osm_file = open(OSM_f, \"r\")    \n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'], regex, expected)\n",
    "\n",
    "    return street_types\n",
    "\n",
    "pprint.pprint(dict(audit(OSM_f, regex))) # print the existing names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update street name by replaceing unexpected street names with better names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return the updated names\n",
    "def update_name(name, mapping, regex):  \n",
    "    m = regex.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            name = re.sub(regex, mapping[street_type], name)\n",
    "\n",
    "    return name\n",
    "\n",
    "update_street = audit(OSM_f, regex) \n",
    "\n",
    "# print the updated names\n",
    "for street_type, ways in update_street.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping, regex)\n",
    "        print name, \"=>\", better_name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find and replace the abbreviated cardinal points, North, South, East, and West"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardinal_points = audit(OSM_f, regexc)\n",
    "\n",
    "pprint.pprint(dict(cardinal_points))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cardinal_mapping = {'N'  : 'North', \n",
    "                    'N.' : 'North',\n",
    "                    'E.' : 'East',\n",
    "                    'E'  : 'East',\n",
    "                    'W'  : 'West',\n",
    "                    'W.' : 'West',\n",
    "                    'S'  : 'South',\n",
    "                    'S.' : 'South'}\n",
    "\n",
    "for cardinal_points, ways in cardinal_points.iteritems():  \n",
    "    if cardinal_points in cardinal_mapping:\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping, regex)\n",
    "            nice_name   = update_name(better_name, cardinal_mapping, regexc)\n",
    "            print name, \"=>\", better_name, \"=>\", nice_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postal Codes\n",
    "After cleaning the street names, now we are going to audite and clean the postal code for Houston area.Postal codes for Houston is 5-numeric starting with 77. So for  consistency we are going to clean up al zip code that does not Houston area zip codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit_zipcodes(OSMFILE):\n",
    "    # iter through all zip codes, collect all the zip codes that does not start with 77\n",
    "    \n",
    "    zip_codes = {}\n",
    "    for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == \"addr:postcode\" and not tag.attrib['v'].startswith('77'):\n",
    "                    if tag.attrib['v'] not in zip_codes:\n",
    "                        zip_codes[tag.attrib['v']] = 1\n",
    "                    else:\n",
    "                        zip_codes[tag.attrib['v']] += 1\n",
    "    return zip_codes\n",
    "\n",
    "zipcodes = audit_zipcodes(OSMFILE)\n",
    "for zipcode in zipcodes:\n",
    "    print (zipcode, zipcodes[zipcode])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
